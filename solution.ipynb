{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4ec0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete. Target Model: llama3.1\n",
      "‚ö†Ô∏è Processing limited to first 10 rows for testing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from ddgs import DDGS\n",
    "import csv\n",
    "import time\n",
    "\n",
    "MODEL_NAME = \"llama3.1\"\n",
    "INPUT_FILE = \"overbase_list.csv\"\n",
    "MISSING_DATA_FILE = \"missing_data_rows.csv\"\n",
    "OUTPUT_FILE = \"processed_leads_sample.csv\"\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "print(f\"‚úÖ Setup complete. Target Model: {MODEL_NAME}\")\n",
    "print(f\"‚ö†Ô∏è Processing limited to first {BATCH_SIZE} rows for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01691ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading and cleaning data...\n",
      "   - Saved 81 rows with missing info to 'missing_data_rows.csv'\n",
      "‚úÖ Total valid rows loaded: 294\n"
     ]
    }
   ],
   "source": [
    "def clean_and_load_data(filepath):\n",
    "    valid_rows = []\n",
    "    missing_data_rows = []\n",
    "    \n",
    "    # Define all variations of \"missing\" found in your file\n",
    "    INVALID_VALUES = {'', '-', '‚Äî', '‚Äì', 'n/a', 'nan', 'none'}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None) # Skip header\n",
    "            \n",
    "            for row in reader:\n",
    "                if not row: continue\n",
    "                \n",
    "                name, title, company = None, None, None\n",
    "                \n",
    "                # Logic for column variations\n",
    "                if len(row) == 4:\n",
    "                    name, title, company = row[0], row[1], row[2]\n",
    "                elif len(row) >= 5:\n",
    "                    name, title, company = row[0], row[1], row[3] # 4th column is company\n",
    "                else:\n",
    "                    missing_data_rows.append(row)\n",
    "                    continue\n",
    "\n",
    "                # 1. Clean whitespace\n",
    "                name = name.strip() if name else \"\"\n",
    "                title = title.strip() if title else \"\"\n",
    "                company = company.strip() if company else \"\"\n",
    "\n",
    "                # 2. Check against invalid values list\n",
    "                is_title_bad = not title or title.lower() in INVALID_VALUES\n",
    "                is_company_bad = not company or company.lower() in INVALID_VALUES\n",
    "\n",
    "                # 3. Filter\n",
    "                if is_title_bad or is_company_bad:\n",
    "                    missing_data_rows.append(row)\n",
    "                else:\n",
    "                    valid_rows.append({'Name': name, 'Title': title, 'Company': company})\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(valid_rows), pd.DataFrame(missing_data_rows)\n",
    "\n",
    "# Execute Load\n",
    "print(\"üìÇ Loading and cleaning data...\")\n",
    "df, df_missing = clean_and_load_data(INPUT_FILE)\n",
    "\n",
    "# Remove Duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Save missing data\n",
    "if not df_missing.empty:\n",
    "    df_missing.to_csv(MISSING_DATA_FILE, index=False, header=False)\n",
    "    print(f\"   - Saved {len(df_missing)} rows with missing info to '{MISSING_DATA_FILE}'\")\n",
    "\n",
    "print(f\"‚úÖ Total valid rows loaded: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4b6953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è  Dataset successfully trimmed to first 10 rows for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donna Johnson</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>Inseego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andreas Urschitz</td>\n",
       "      <td>CMO</td>\n",
       "      <td>Infineon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Julia Chen</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>AWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert Occhialini</td>\n",
       "      <td>Chief Technology Officer</td>\n",
       "      <td>World Surf League</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gabriel Romero</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>AllCloud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                     Title            Company\n",
       "0      Donna Johnson   Chief Marketing Officer            Inseego\n",
       "1   Andreas Urschitz                       CMO           Infineon\n",
       "2         Julia Chen            Vice President                AWS\n",
       "3  Robert Occhialini  Chief Technology Officer  World Surf League\n",
       "4     Gabriel Romero   Chief Marketing Officer           AllCloud"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- LIMITING DATASET ---\n",
    "if len(df) > BATCH_SIZE:\n",
    "    df = df.head(BATCH_SIZE).copy()\n",
    "    print(f\"‚úÇÔ∏è  Dataset successfully trimmed to first {BATCH_SIZE} rows for testing.\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  Dataset is smaller than {BATCH_SIZE}, processing all rows.\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a8d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AI Agents initialized.\n"
     ]
    }
   ],
   "source": [
    "def search_web(query, max_results=3):\n",
    "    \"\"\"Searches DuckDuckGo and returns a summary string.\"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=max_results)\n",
    "        if not results: return \"\"\n",
    "        return \"\\n\".join([f\"- {r['body']}\" for r in results])\n",
    "    except Exception as e:\n",
    "        print(f\"   [Search Error] {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def ask_ollama(prompt, context=\"\"):\n",
    "    \"\"\"Queries the local Llama 3.2 model.\"\"\"\n",
    "    full_prompt = f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Instruction:\n",
    "    {prompt}\n",
    "    \n",
    "    Output Rules:\n",
    "    - Output ONLY the answer requested.\n",
    "    - No conversational filler (e.g., \"Here is the answer\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'user', 'content': full_prompt},\n",
    "        ])\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ AI Agents initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f84f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Processing 10 rows...\n",
      "   - Filtering for Senior Executives...\n",
      "   - 10 Executives remaining.\n",
      "   - Fetching Domains & Verifying Employment...\n",
      "   - Generating Emails (splitting into 2 columns)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Is_Senior</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Generated_Emails</th>\n",
       "      <th>Email_1</th>\n",
       "      <th>Email_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donna Johnson</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>Inseego</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>True</td>\n",
       "      <td>inseego.com</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>donna.johnson@inseego.com, djohnson@inseego.com</td>\n",
       "      <td>donna.johnson@inseego.com</td>\n",
       "      <td>donna.johnson1@inseego.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andreas Urschitz</td>\n",
       "      <td>CMO</td>\n",
       "      <td>Infineon</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>Urschitz</td>\n",
       "      <td>True</td>\n",
       "      <td>infineon.com</td>\n",
       "      <td>Likely Yes</td>\n",
       "      <td>Andreas.Urschitz@infineon.com, andreas.urschit...</td>\n",
       "      <td>andreas.urschitz@infineon.com</td>\n",
       "      <td>andrea.urschitz@infineon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Julia Chen</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Chen</td>\n",
       "      <td>True</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>jchen@amazon.com, jchen@aws.com</td>\n",
       "      <td>julia.chen@amazon.com</td>\n",
       "      <td>julia.chen+bounce@amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert Occhialini</td>\n",
       "      <td>Chief Technology Officer</td>\n",
       "      <td>World Surf League</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Occhialini</td>\n",
       "      <td>True</td>\n",
       "      <td>worldsurfleague.com</td>\n",
       "      <td>Likely Yes</td>\n",
       "      <td>R.Occhialini@worldsurfleague.com, Rob_Occhiali...</td>\n",
       "      <td>robert.occhialini@worldsurfleague.com</td>\n",
       "      <td>rob.o@worldsurfleague.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gabriel Romero</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>AllCloud</td>\n",
       "      <td>Gabriel</td>\n",
       "      <td>Romero</td>\n",
       "      <td>True</td>\n",
       "      <td>.cloud</td>\n",
       "      <td>Likely Yes</td>\n",
       "      <td>gabriel.rodriguez@googole.com, gabrielromero@g...</td>\n",
       "      <td>gabriel@get.cloud</td>\n",
       "      <td>gabrielpablo@get.cloud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                     Title            Company First_Name  \\\n",
       "0      Donna Johnson   Chief Marketing Officer            Inseego      Donna   \n",
       "1   Andreas Urschitz                       CMO           Infineon    Andreas   \n",
       "2         Julia Chen            Vice President                AWS      Julia   \n",
       "3  Robert Occhialini  Chief Technology Officer  World Surf League     Robert   \n",
       "4     Gabriel Romero   Chief Marketing Officer           AllCloud    Gabriel   \n",
       "\n",
       "    Last_Name  Is_Senior               Domain Employment_Status  \\\n",
       "0     Johnson       True          inseego.com         Uncertain   \n",
       "1    Urschitz       True         infineon.com        Likely Yes   \n",
       "2        Chen       True           amazon.com         Uncertain   \n",
       "3  Occhialini       True  worldsurfleague.com        Likely Yes   \n",
       "4      Romero       True               .cloud        Likely Yes   \n",
       "\n",
       "                                    Generated_Emails  \\\n",
       "0    donna.johnson@inseego.com, djohnson@inseego.com   \n",
       "1  Andreas.Urschitz@infineon.com, andreas.urschit...   \n",
       "2                    jchen@amazon.com, jchen@aws.com   \n",
       "3  R.Occhialini@worldsurfleague.com, Rob_Occhiali...   \n",
       "4  gabriel.rodriguez@googole.com, gabrielromero@g...   \n",
       "\n",
       "                                 Email_1                       Email_2  \n",
       "0              donna.johnson@inseego.com    donna.johnson1@inseego.com  \n",
       "1          andreas.urschitz@infineon.com  andrea.urschitz@infineon.com  \n",
       "2                  julia.chen@amazon.com  julia.chen+bounce@amazon.com  \n",
       "3  robert.occhialini@worldsurfleague.com     rob.o@worldsurfleague.com  \n",
       "4                      gabriel@get.cloud        gabrielpablo@get.cloud  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"üöÄ Processing {len(df)} rows...\")\n",
    "\n",
    "# 1. Split Names\n",
    "def split_name(full_name):\n",
    "    parts = str(full_name).strip().split()\n",
    "    first = parts[0]\n",
    "    last = \" \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
    "    return pd.Series([first, last])\n",
    "\n",
    "df[['First_Name', 'Last_Name']] = df['Name'].apply(split_name)\n",
    "\n",
    "# 2. Filter Senior Executives (Local AI)\n",
    "print(\"   - Filtering for Senior Executives...\")\n",
    "def is_senior(title):\n",
    "    res = ask_ollama(f\"Is '{title}' a Senior Executive role (VP, C-Level, Director, Head)? YES/NO.\")\n",
    "    return \"YES\" in res.upper()\n",
    "\n",
    "df['Is_Senior'] = df['Title'].apply(is_senior)\n",
    "df = df[df['Is_Senior']].copy()\n",
    "print(f\"   - {len(df)} Executives remaining.\")\n",
    "\n",
    "# 3. Domain & Employment (Web Search)\n",
    "print(\"   - Fetching Domains & Verifying Employment...\")\n",
    "\n",
    "def enrich_data(row):\n",
    "    # Get Domain\n",
    "    domain_context = search_web(f\"official website domain for {row['Company']}\")\n",
    "    domain = ask_ollama(f\"Extract main domain (e.g. google.com) from: {domain_context}\", domain_context)\n",
    "    domain = domain.lower().replace(\"www.\", \"\").split('/')[0]\n",
    "    \n",
    "    # Verify Employment\n",
    "    work_context = search_web(f\"Is {row['Name']} still working at {row['Company']} 2024 2025?\")\n",
    "    still_working = ask_ollama(f\"Is {row['Name']} still at {row['Company']}? Answer 'Likely Yes', 'Likely No', or 'Uncertain'.\", work_context)\n",
    "    \n",
    "    return pd.Series([domain, still_working])\n",
    "\n",
    "if not df.empty:\n",
    "    df[['Domain', 'Employment_Status']] = df.apply(enrich_data, axis=1)\n",
    "\n",
    "# 4. Generate Emails into 2 Fields\n",
    "print(\"   - Generating Emails (splitting into 2 columns)...\")\n",
    "\n",
    "def get_emails(row):\n",
    "    if row['Domain'] in ['n/a', '']: \n",
    "        return pd.Series([\"N/A\", \"N/A\"])\n",
    "    \n",
    "    pattern_ctx = search_web(f\"email format for {row['Company']} {row['Domain']}\")\n",
    "    \n",
    "    # Prompt specific for comma separation\n",
    "    prompt = f\"\"\"\n",
    "    Generate 2 likely email addresses for {row['First_Name']} {row['Last_Name']} @{row['Domain']} based on context.\n",
    "    Output ONLY the two emails separated by a comma (e.g. email1, email2).\n",
    "    Do not add numbering or extra text.\n",
    "    \"\"\"\n",
    "    response = ask_ollama(prompt, pattern_ctx)\n",
    "    \n",
    "    # Logic to split string into two fields\n",
    "    try:\n",
    "        # Remove newlines and split by comma\n",
    "        emails = response.replace('\\n', ' ').split(',')\n",
    "        email1 = emails[0].strip()\n",
    "        email2 = emails[1].strip() if len(emails) > 1 else \"\"\n",
    "    except:\n",
    "        email1, email2 = response, \"\"\n",
    "        \n",
    "    return pd.Series([email1, email2])\n",
    "\n",
    "if not df.empty:\n",
    "    # Assigning to two new columns directly\n",
    "    df[['Email_1', 'Email_2']] = df.apply(get_emails, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17bf1f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! Processed data saved to: processed_leads_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Define final column order\n",
    "final_columns = [\n",
    "    'Name', \n",
    "    'First_Name', \n",
    "    'Last_Name', \n",
    "    'Title', \n",
    "    'Company', \n",
    "    'Domain', \n",
    "    'Employment_Status', \n",
    "    'Email_1', \n",
    "    'Email_2'\n",
    "]\n",
    "\n",
    "if not df.empty:\n",
    "    # Ensure all columns exist before saving (handles case where filtering removed everything)\n",
    "    available_cols = [c for c in final_columns if c in df.columns]\n",
    "    df[available_cols].to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"‚úÖ Done! Processed data saved to: {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data remaining after filtering.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
