{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from ddgs import DDGS\n",
    "import csv\n",
    "import time\n",
    "\n",
    "MODEL_NAME = \"llama3.1\"\n",
    "INPUT_FILE = \"overbase_list.csv\"\n",
    "MISSING_DATA_FILE = \"missing_data_rows.csv\"\n",
    "OUTPUT_FILE = \"processed_leads_sample.csv\"\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_load_data(filepath):\n",
    "    valid_rows = []\n",
    "    missing_data_rows = []\n",
    "    \n",
    "    # Define all variations of \"missing\" found in your file\n",
    "    INVALID_VALUES = {'', '-', '‚Äî', '‚Äì', 'n/a', 'nan', 'none'}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None) # Skip header\n",
    "            \n",
    "            for row in reader:\n",
    "                if not row: continue\n",
    "                \n",
    "                name, title, company = None, None, None\n",
    "                \n",
    "                # Logic for column variations\n",
    "                if len(row) == 4:\n",
    "                    name, title, company = row[0], row[1], row[2]\n",
    "                elif len(row) >= 5:\n",
    "                    name, title, company = row[0], row[1], row[3] # 4th column is company\n",
    "                else:\n",
    "                    missing_data_rows.append(row)\n",
    "                    continue\n",
    "\n",
    "                # 1. Clean whitespace\n",
    "                name = name.strip() if name else \"\"\n",
    "                title = title.strip() if title else \"\"\n",
    "                company = company.strip() if company else \"\"\n",
    "\n",
    "                # 2. Check against invalid values list\n",
    "                is_title_bad = not title or title.lower() in INVALID_VALUES\n",
    "                is_company_bad = not company or company.lower() in INVALID_VALUES\n",
    "\n",
    "                # 3. Filter\n",
    "                if is_title_bad or is_company_bad:\n",
    "                    missing_data_rows.append(row)\n",
    "                else:\n",
    "                    valid_rows.append({'Name': name, 'Title': title, 'Company': company})\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(valid_rows), pd.DataFrame(missing_data_rows)\n",
    "\n",
    "# Execute Load\n",
    "print(\"üìÇ Loading and cleaning data...\")\n",
    "# Remove Duplicates\n",
    "df = df.drop_duplicates()\n",
    "df, df_missing = clean_and_load_data(INPUT_FILE)\n",
    "\n",
    "# Save missing data\n",
    "if not df_missing.empty:\n",
    "    df_missing.to_csv(MISSING_DATA_FILE, index=False, header=False)\n",
    "    print(f\"   - Saved {len(df_missing)} rows with missing info to '{MISSING_DATA_FILE}'\")\n",
    "\n",
    "print(f\"‚úÖ Total valid rows loaded: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > BATCH_SIZE:\n",
    "    df = df.head(BATCH_SIZE).copy()\n",
    "    print(f\"‚úÇÔ∏è  Dataset successfully trimmed to first {BATCH_SIZE} rows for testing.\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  Dataset is smaller than {BATCH_SIZE}, processing all rows.\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(query, max_results=3):\n",
    "    \"\"\"Searches DuckDuckGo and returns a summary string.\"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=max_results)\n",
    "        if not results: return \"\"\n",
    "        return \"\\n\".join([f\"- {r['body']}\" for r in results])\n",
    "    except Exception as e:\n",
    "        print(f\"   [Search Error] {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def ask_ollama(prompt, context=\"\"):\n",
    "    \"\"\"Queries the local Llama 3.1 model.\"\"\"\n",
    "    full_prompt = f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Instruction:\n",
    "    {prompt}\n",
    "    \n",
    "    Output Rules:\n",
    "    - Output ONLY the answer requested.\n",
    "    - No conversational filler (e.g., \"Here is the answer\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'user', 'content': full_prompt},\n",
    "        ])\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ AI Agents initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f84f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üöÄ Processing {len(df)} rows...\")\n",
    "\n",
    "# 1. Split Names\n",
    "def split_name(full_name):\n",
    "    parts = str(full_name).strip().split()\n",
    "    first = parts[0]\n",
    "    last = \" \".join(parts[1:]) if len(parts) > 1 else \"\"\n",
    "    return pd.Series([first, last])\n",
    "\n",
    "df[['First_Name', 'Last_Name']] = df['Name'].apply(split_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb174a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter Senior Executives (Local AI)\n",
    "print(\"   - Filtering for Senior Executives...\")\n",
    "def is_senior(title):\n",
    "    res = ask_ollama(f\"Is '{title}' a Senior Executive role (C-Level, Founder)? YES/NO.\")\n",
    "    return \"YES\" in res.upper()\n",
    "\n",
    "df['Is_Senior'] = df['Title'].apply(is_senior)\n",
    "df = df[df['Is_Senior']].copy()\n",
    "print(f\"   - {len(df)} Executives remaining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Domain & Employment (Web Search)\n",
    "print(\"   - Fetching Domains & Verifying Employment...\")\n",
    "\n",
    "def enrich_data(row):\n",
    "    # Get Domain\n",
    "    domain_context = search_web(f\"official website domain for {row['Company']}\")\n",
    "    domain = ask_ollama(f\"Extract main domain (e.g. google.com) from: {domain_context}\", domain_context)\n",
    "    domain = domain.lower().replace(\"www.\", \"\").split('/')[0]\n",
    "    \n",
    "    # Verify Employment\n",
    "    work_context = search_web(f\"{row['Name']} {row['Company']} 2025 LinkedIn?\")\n",
    "    still_working = ask_ollama(f\"Is {row['Name']} working in {row['Company']} at the position of {row['Title']} currently? Answer 'Likely Yes', 'Likely No', or 'Uncertain'.\", work_context)\n",
    "    \n",
    "    return pd.Series([domain, still_working])\n",
    "\n",
    "if not df.empty:\n",
    "    df[['Domain', 'Employment_Status']] = df.apply(enrich_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate Emails into 2 Fields\n",
    "print(\"   - Generating Emails (splitting into 2 columns)...\")\n",
    "\n",
    "def get_emails(row):\n",
    "    if row['Domain'] in ['n/a', '']: \n",
    "        return pd.Series([\"N/A\", \"N/A\"])\n",
    "    \n",
    "    pattern_ctx = search_web(f\"email format for {row['Company']} {row['Domain']}\")\n",
    "    \n",
    "    # Prompt specific for comma separation\n",
    "    prompt = f\"\"\"\n",
    "    Generate 2 likely email addresses for {row['First_Name']} {row['Last_Name']} {row['Domain']} based on context.\n",
    "    Output ONLY the two emails separated by a comma (e.g. email1, email2).\n",
    "    Do not add numbering or extra text.\n",
    "    \"\"\"\n",
    "    response = ask_ollama(prompt, pattern_ctx)\n",
    "    \n",
    "    # Logic to split string into two fields\n",
    "    try:\n",
    "        # Remove newlines and split by comma\n",
    "        emails = response.replace('\\n', ' ').split(',')\n",
    "        email1 = emails[0].strip()\n",
    "        email2 = emails[1].strip() if len(emails) > 1 else \"\"\n",
    "    except:\n",
    "        email1, email2 = response, \"\"\n",
    "        \n",
    "    return pd.Series([email1, email2])\n",
    "\n",
    "if not df.empty:\n",
    "    # Assigning to two new columns directly\n",
    "    df[['Email_1', 'Email_2']] = df.apply(get_emails, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final column order\n",
    "final_columns = [\n",
    "    'Name', \n",
    "    'First_Name', \n",
    "    'Last_Name', \n",
    "    'Title', \n",
    "    'Company', \n",
    "    'Domain', \n",
    "    'Employment_Status', \n",
    "    'Email_1', \n",
    "    'Email_2'\n",
    "]\n",
    "\n",
    "if not df.empty:\n",
    "    # Ensure all columns exist before saving (handles case where filtering removed everything)\n",
    "    available_cols = [c for c in final_columns if c in df.columns]\n",
    "    df[available_cols].to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"‚úÖ Done! Processed data saved to: {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data remaining after filtering.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
